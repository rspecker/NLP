{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Natural Language Project - Finding the Genre of Movie Plots - Group 11"
      ],
      "metadata": {
        "id": "0KWwPuQ9iq-c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Project Setup\n",
        "If you're running this project in **Google Colab**, make sure to execute the following commands to properly configure the environment.\n",
        "(These steps are not required if you're running the project locally on your machine.)"
      ],
      "metadata": {
        "id": "TF6xI_Yyjv5D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/rspecker/NLP.git\n",
        "%cd NLP"
      ],
      "metadata": {
        "id": "P4u_gh5Dm3Yd",
        "outputId": "c0f53c60-82e6-4723-bf20-019553c87211",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'NLP'...\n",
            "remote: Enumerating objects: 289, done.\u001b[K\n",
            "remote: Counting objects: 100% (31/31), done.\u001b[K\n",
            "remote: Compressing objects: 100% (26/26), done.\u001b[K\n",
            "remote: Total 289 (delta 16), reused 12 (delta 5), pack-reused 258 (from 1)\u001b[K\n",
            "Receiving objects: 100% (289/289), 16.95 MiB | 16.86 MiB/s, done.\n",
            "Resolving deltas: 100% (167/167), done.\n",
            "/content/NLP\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !git pull"
      ],
      "metadata": {
        "id": "hasncwaU0-GJ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install -r requirements.txt"
      ],
      "metadata": {
        "collapsed": true,
        "id": "NWcgfqmAm9SK"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install sentence-transformers"
      ],
      "metadata": {
        "id": "Lgi96A6St8rT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import project dependencies\n",
        "import pandas as pd\n",
        "from modelling.grid import classifiers\n",
        "from modelling.grid_search import perform_grid_search\n",
        "from modelling.evaluation import evaluate_model, save_results_to_file, save_confusion_matrix, save_test_data_with_predictions, apply_model_to_unlabeled_data\n",
        "from preprocessing.embeddings import create_sentence_embeddings\n",
        "from preprocessing.preproc import create_preprocesssed_dataset\n",
        "from preprocessing.tfidf import create_train_data_tfidf\n",
        "from utils import create_train_test_sets\n",
        "from modelling.information_ret import score"
      ],
      "metadata": {
        "id": "t6mFyY_8-y1Q"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Import"
      ],
      "metadata": {
        "id": "Wz-HMKTfp4C3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import data and set column names\n",
        "df = pd.read_table(\n",
        "    'train.txt',\n",
        "    names=['title', 'from', 'genre', 'director', 'plot']\n",
        "    )"
      ],
      "metadata": {
        "id": "8_hSmeDU8tzq"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import data without labels and set column names\n",
        "df_no_labels = pd.read_table(\n",
        "    'test_no_labels.txt',\n",
        "    names=['title', 'from', 'director', 'plot']\n",
        "    )"
      ],
      "metadata": {
        "id": "c5u0gxTtsixN"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Pre-Processing"
      ],
      "metadata": {
        "id": "8Lzimx4u-W8D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into training and testing sets\n",
        "x_train, x_test, y_train, y_test = create_train_test_sets(\n",
        "    df, test_size=0.2, random_state=0, y_column='genre'\n",
        ")"
      ],
      "metadata": {
        "id": "3oeryi30-WZj"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TF-IDF\n",
        "TF-IDF converts text into sparse vectors based on word importance across documents, without considering word order or context"
      ],
      "metadata": {
        "id": "CouWhn3ZDqGq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create TF-IDF\n",
        "vectorizer, x_train_tfidf = create_train_data_tfidf(x_train)"
      ],
      "metadata": {
        "id": "CedZfecfDIGz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a49e4fb2-0489-4300-cf26-9adb5479dcfd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer, x_test_tfidf = create_train_data_tfidf(x_test, vectorizer)"
      ],
      "metadata": {
        "id": "dJBhXct50Klm"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer, no_labels_tfidf = create_train_data_tfidf(df_no_labels, vectorizer)"
      ],
      "metadata": {
        "id": "NuGtjchItBqt"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature-based Transfer Learning with Sentence Embeddings (Sentence-BERT)\n",
        "Sentence-BERT generates dense, fixed-length embeddings that capture the semantic meaning of entire sentences, enabling more context-aware comparisons."
      ],
      "metadata": {
        "id": "YlBPXDHyDy4h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create sentence embeddings for testing data\n",
        "x_train_sentence_embeddings = create_sentence_embeddings(\n",
        "    sentences=x_train[\"plot\"].to_list(),\n",
        "    model=\"all-MiniLM-L6-v2\")"
      ],
      "metadata": {
        "id": "micwxtCQEx4s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create sentence embeddings for testing data\n",
        "x_test_sentence_embeddings = create_sentence_embeddings(\n",
        "    sentences=x_test[\"plot\"].to_list(),\n",
        "    model=\"all-MiniLM-L6-v2\")"
      ],
      "metadata": {
        "id": "GOQT3Up3uUcg"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create sentence embeddings for unlabelled data\n",
        "no_labels_sentence_embeddings = create_sentence_embeddings(\n",
        "    sentences=df_no_labels[\"plot\"].to_list(),\n",
        "    model=\"all-MiniLM-L6-v2\")"
      ],
      "metadata": {
        "id": "UJU9U-SotPYy"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "E4tfS-b8qjqi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TF-IDF"
      ],
      "metadata": {
        "id": "1yWABUlEvhv6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "del classifiers[\"MultinomialNB\"]"
      ],
      "metadata": {
        "id": "JRpbblid0WwM"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for model_name, (model, param_grid) in classifiers.items():\n",
        "    model_type=\"word_embeddings\"\n",
        "    # Perform GridSearchCV\n",
        "    best_model, best_params, best_score = perform_grid_search(\n",
        "        model, param_grid, model_type,model_name,\n",
        "        x_train_tfidf, y_train)\n",
        "\n",
        "    # Evaluate the model\n",
        "    y_pred, test_accuracy, classification_rep, cm = evaluate_model(\n",
        "        best_model, x_test_tfidf, y_test)\n",
        "\n",
        "    # Save the results\n",
        "    save_results_to_file(\n",
        "        model_type, model_name, best_params, best_score, test_accuracy, classification_rep)\n",
        "\n",
        "    save_test_data_with_predictions(x_test, y_test, y_pred, model_type, model_name)\n",
        "\n",
        "    # Save confusion matrix as image\n",
        "    save_confusion_matrix(model_type, model_name, cm, y_test)\n",
        "\n",
        "    # Apply model to unlabeled data\n",
        "    apply_model_to_unlabeled_data(best_model, no_labels_tfidf, model_type, model_name)"
      ],
      "metadata": {
        "id": "7_t3V7ep0QYc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature-based Transfer Learning with Sentence Embeddings (Sentence-BERT)"
      ],
      "metadata": {
        "id": "U7zS3sd-vlCm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# del classifiers[\"MultinomialNB\"]"
      ],
      "metadata": {
        "id": "JdECuVaFAhcH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for model_name, (model, param_grid) in classifiers.items():\n",
        "    model_type=\"sentence_embeddings\"\n",
        "    # Perform GridSearchCV\n",
        "    best_model, best_params, best_score = perform_grid_search(\n",
        "        model, param_grid, model_type,model_name,\n",
        "        x_train_sentence_embeddings, y_train)\n",
        "\n",
        "    # Evaluate the model\n",
        "    y_pred, test_accuracy, classification_rep, cm = evaluate_model(\n",
        "        best_model, x_test_sentence_embeddings, y_test)\n",
        "\n",
        "    # Save the results\n",
        "    save_results_to_file(\n",
        "        model_type, model_name, best_params, best_score, test_accuracy, classification_rep)\n",
        "    save_test_data_with_predictions(x_test, y_test, y_pred, model_type, model_name)\n",
        "\n",
        "    # Save confusion matrix as image\n",
        "    save_confusion_matrix(model_type, model_name, cm, y_test)\n",
        "\n",
        "\n",
        "    # Apply model to unlabeled data\n",
        "    apply_model_to_unlabeled_data(best_model, no_labels_sentence_embeddings, model_type, model_name)"
      ],
      "metadata": {
        "id": "Eht55-U3vgw1",
        "outputId": "6a5017d2-5e36-4615-be48-714ee0719489",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
            "Fitting 5 folds for each of 324 candidates, totalling 1620 fits\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}