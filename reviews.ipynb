{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Natural Language Project - Finding the Genre of Movie Plots - Group 11"
      ],
      "metadata": {
        "id": "0KWwPuQ9iq-c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Project Setup\n",
        "If you're running this project in **Google Colab**, make sure to execute the following commands to properly configure the environment.\n",
        "(These steps are not required if you're running the project locally on your machine.)"
      ],
      "metadata": {
        "id": "TF6xI_Yyjv5D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/rspecker/NLP.git\n",
        "%cd NLP"
      ],
      "metadata": {
        "id": "P4u_gh5Dm3Yd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install -r requirements.txt"
      ],
      "metadata": {
        "collapsed": true,
        "id": "NWcgfqmAm9SK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install sentence-transformers"
      ],
      "metadata": {
        "id": "Lgi96A6St8rT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer"
      ],
      "metadata": {
        "id": "IU-3qzDhtlIn",
        "outputId": "6fa4b97d-11df-4068-d060-ea23491d7066",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  from tqdm.autonotebook import tqdm, trange\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import project dependencies\n",
        "import pandas as pd\n",
        "from preprocessing.embeddings import create_sentence_embeddings\n",
        "from preprocessing.preproc import create_preprocesssed_dataset\n",
        "from preprocessing.tfidf import create_train_data_tfidf\n",
        "from utils import create_train_test_sets\n",
        "from modelling.information_ret import score"
      ],
      "metadata": {
        "id": "t6mFyY_8-y1Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Import"
      ],
      "metadata": {
        "id": "Wz-HMKTfp4C3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import data and set column names\n",
        "df = pd.read_table(\n",
        "    'train.txt',\n",
        "    names=['title', 'from', 'genre', 'director', 'plot']\n",
        "    )"
      ],
      "metadata": {
        "id": "8_hSmeDU8tzq"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Pre-Processing"
      ],
      "metadata": {
        "id": "8Lzimx4u-W8D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into training and testing sets\n",
        "x_train, x_test, y_train, y_test = create_train_test_sets(\n",
        "    df, test_size=0.2, random_state=0, y_column='genre'\n",
        ")"
      ],
      "metadata": {
        "id": "3oeryi30-WZj"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TF-IDF\n",
        "TF-IDF converts text into sparse vectors based on word importance across documents, without considering word order or context"
      ],
      "metadata": {
        "id": "CouWhn3ZDqGq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create TF-IDF"
      ],
      "metadata": {
        "id": "CedZfecfDIGz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature-based Transfer Learning with Sentence Embeddings (Sentence-BERT)\n",
        "Sentence-BERT generates dense, fixed-length embeddings that capture the semantic meaning of entire sentences, enabling more context-aware comparisons."
      ],
      "metadata": {
        "id": "YlBPXDHyDy4h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create sentence embeddings for testing data\n",
        "x_train_sentence_embeddings = create_sentence_embeddings(\n",
        "    sentences=x_train[\"plot\"].to_list(),\n",
        "    model=\"all-MiniLM-L6-v2\")"
      ],
      "metadata": {
        "id": "micwxtCQEx4s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create sentence embeddings for testing data\n",
        "x_test_sentence_embeddings = create_sentence_embeddings(\n",
        "    sentences=x_test[\"plot\"].to_list(),\n",
        "    model=\"all-MiniLM-L6-v2\")"
      ],
      "metadata": {
        "id": "GOQT3Up3uUcg"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "E4tfS-b8qjqi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TF-IDF"
      ],
      "metadata": {
        "id": "1yWABUlEvhv6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature-based Transfer Learning with Sentence Embeddings (Sentence-BERT)"
      ],
      "metadata": {
        "id": "U7zS3sd-vlCm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for model_name, (model, param_grid) in models.items():\n",
        "    # Perform GridSearchCV\n",
        "    grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, n_jobs=-1, verbose=1)\n",
        "    grid_search.fit(X_train, y_train)\n",
        "\n",
        "    # Get the best parameters and score\n",
        "    best_params = grid_search.best_params_\n",
        "    best_score = grid_search.best_score_\n",
        "\n",
        "    # Test the best model on the test set\n",
        "    best_model = grid_search.best_estimator_\n",
        "    y_pred = best_model.predict(X_test)\n",
        "\n",
        "    # Calculate accuracy and classification report\n",
        "    test_accuracy = accuracy_score(y_test, y_pred)\n",
        "    classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "    # Create a text file for each model's results\n",
        "    result_file_path = f'results/{model_name}_grid_search_results.txt'\n",
        "    with open(result_file_path, 'w') as result_file:\n",
        "        result_file.write(f\"Model: {model_name}\\n\")\n",
        "        result_file.write(f\"Best Parameters: {best_params}\\n\")\n",
        "        result_file.write(f\"Best Cross-Validation Score: {best_score:.4f}\\n\")\n",
        "        result_file.write(f\"Test Accuracy: {test_accuracy:.4f}\\n\")\n",
        "        result_file.write(f\"Classification Report:\\n{classification_rep}\\n\")\n",
        "\n",
        "    # Create confusion matrix\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    # Plot confusion matrix\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=np.unique(y_test))\n",
        "    disp.plot(cmap=plt.cm.Blues)\n",
        "\n",
        "    # Save confusion matrix as an image\n",
        "    plt.title(f'Confusion Matrix for {model_name}')\n",
        "    plt.savefig(f'results/{model_name}_confusion_matrix.png')\n",
        "    plt.close()"
      ],
      "metadata": {
        "id": "Eht55-U3vgw1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "dzMPouhBijpb"
      },
      "outputs": [],
      "source": [
        "vectorizer = TfidfVectorizer(max_features=1000)\n",
        "x_train_tfidf = vectorizer.fit_transform(x_train[\"plot\"])\n",
        "x_test_tfidf = vectorizer.transform(x_test[\"plot\"])\n",
        "\n",
        "model = MultinomialNB()\n",
        "params, score = tune_hyperparameters(model, mnb_param_grid, x_train_tfidf, y_train)\n",
        "\n",
        "final_model = MultinomialNB(alpha=params['alpha'],\n",
        "                            fit_prior=params['fit_prior'])\n",
        "final_model.fit(x_train_tfidf, y_train)\n",
        "\n",
        "final_model.score(x_test_tfidf, y_test)\n",
        "print(f\"Test set accuracy: {final_model.score(x_test_tfidf, y_test)}\")\n",
        "\n",
        "model = SVC()\n",
        "params, score = tune_hyperparameters(model, svc_param_grid, x_train_tfidf, y_train)\n",
        "\n",
        "final_model = MultinomialNB(C=params['C'],\n",
        "                            kernel=params['kernel'],\n",
        "                            # gamma=params['gamma'],\n",
        "                            # class_weight=params['class_weight']\n",
        "                            )\n",
        "final_model.fit(x_train_tfidf, y_train)\n",
        "\n",
        "final_model.score(x_test_tfidf, y_test)\n",
        "print(f\"Test set accuracy: {final_model.score(x_test_tfidf, y_test)}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}